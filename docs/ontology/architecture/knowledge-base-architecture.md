## AgenticTrust Knowledge Base Architecture (OWL / OASF / Data)

This repo designs the ontology in Protégé and uses the **ELK** reasoner, so the “online knowledge base” should be optimized for **OWL 2 EL** (fast classification), versioned ontology publishing, and scalable query over RDF data generated by the indexers.

### Goals

- **Ontology**: `agentictrust-core.owl` + extensions (ERC-8004, ERC-8092, ENS, HOL).
- **Taxonomy**: OASF taxonomy (ideally SKOS-like concept scheme(s) with stable URIs).
- **Data**: AgenticTrust observations/assertions/metadata exported as RDF, queryable via SPARQL and/or GraphQL.
- **Reasoning**: Keep modeling **within OWL-EL** where possible (to align with ELK), and materialize inferences for fast queries.

### Recommended architecture (pragmatic, PROV-friendly)

#### 1) Versioned ontology publishing (static)

- Store canonical OWL files in git (published from `apps/badge-admin/public/ontology/`).
- Publish immutable versions (e.g. `/public/ontology/v0.0.1/...`) and keep “latest” symlinks/paths stable.
- CI step: run “ontology QA” (consistency + EL profile sanity) and generate release artifacts.

#### 2) Knowledge base storage (RDF dataset with named graphs)

Use **named graphs** to separate concerns cleanly:

- **Graph: Ontology core**: `agentictrust-core.owl`
- **Graph: Ontology extensions**: ERC-8004, ERC-8092, ENS, HOL, etc.
- **Graph: OASF taxonomy**: skills/capabilities/protocols as a concept scheme
- **Graph: Data (by source)**: `agentverse`, `hol`, on-chain, etc.
- **Graph: Inferences** (optional): materialized entailments (types, subClass closures, property hierarchies, simple role inferences)

This makes it easy to refresh only the data graphs without reloading the ontologies.

#### 3) Reasoning strategy (ELK-compatible)

Because ELK is an OWL-EL reasoner and most production triple stores don’t run ELK directly:

- **Offline classification/materialization**:
  - Run ELK in CI (or a scheduled job) against the ontology to validate and to compute class hierarchy.
  - If you need ABox inferences, keep them *EL-friendly* and materialize them via:
    - store’s built-in lightweight reasoning, or
    - a rules layer (e.g. SHACL Rules / SPARQL CONSTRUCT / Datalog), or
    - a dedicated materialization job that writes inferred triples into the “Inferences” named graph.
- **Online querying**:
  - Prefer querying against asserted + materialized triples (fast, predictable).

#### 4) Data ingestion (from indexers)

- Indexers export canonical RDF (and optionally N-Quads for named graphs).
- Load into the KB using bulk loaders where available.
- Keep a minimal provenance pattern:
  - assertions as `prov:Activity` (e.g. `agentictrust:SituationAssertion`)
  - asserted situations as `prov:Entity` (e.g. `agentictrust:Situation`)
  - link raw JSON via a separate storage path (object store) and reference by hash/URI in RDF

#### 5) Access layer

- **SPARQL endpoint** for power users and internal analytics.
- Optional **GraphQL/REST** facade for product clients (avoid pushing SPARQL to browsers).
- Public read-only endpoint + private write/load endpoint.

### Deployment options (best “online KB” choices)

#### Option A (best overall for ontology-first + SPARQL + ops): Ontotext GraphDB (Cloud or self-host)

- Strong RDF/SPARQL ergonomics, solid ontology workflows, production-grade.
- Built-in reasoning options (not ELK, but can coexist with offline ELK + materialized inferences).
- Good fit when you want a single “knowledge platform” for ontology + taxonomy + data.

#### Local GraphDB (recommended dev setup)

- Start GraphDB locally with docker-compose:

```bash
docker compose -f apps/indexer/graphdb/docker-compose.yml up -d
```

- Create a repository in the Workbench (once):
  - Open `http://localhost:7200` → **Setup → Repositories → Create new repository**
  - Set repository id to `agentictrust` (or set `GRAPHDB_REPOSITORY`)

- Ingest ontologies + generated agent RDF into GraphDB:

```bash
GRAPHDB_BASE_URL=http://localhost:7200 \
GRAPHDB_REPOSITORY=agentictrust \
pnpm --filter erc8004-indexer graphdb:ingest all --reset
```

#### Option B (best for enterprise app integration + governance): Stardog (Cloud or self-host)

- Strong reasoning + governance + access control story, good for multi-tenant graphs.
- Good fit if you expect complex product-facing APIs and enterprise constraints.

#### Option C (best managed “infra-native” graph): AWS Neptune (or similar managed RDF store)

- Managed ops, scalable, integrates with cloud security/IAM.
- Reasoning is limited; assume **offline materialization** for most inference needs.
- Good fit if your infra is already heavily on AWS and you want managed durability.

#### Open-source fallback (good for dev/test and small prod)

- **Apache Jena Fuseki** (SPARQL server) + a materialization job (SPARQL CONSTRUCT / rules).
- Works well if you treat reasoning as a build step and keep the runtime simple.

### Modeling recommendations for Protégé + ELK

- Stay close to **OWL-EL patterns**:
  - prefer named classes + subclass axioms + property restrictions that are EL-safe
  - avoid constructs that push you out of EL (when possible), or isolate them in a non-EL extension graph
- Use SKOS-like modeling for OASF taxonomy:
  - stable URIs, `prefLabel`, `altLabel`, `broader/narrower`, concept schemes
  - keep taxonomy changes versioned independently from core ontology releases

### Suggested next step (repo-friendly)

- Add a small “kb export” artifact format: **N-Quads** per named graph (ontology, taxonomy, data, inferences).
- Add CI to publish versioned OWL + taxonomy + a downloadable “KB snapshot” for local Fuseki/GraphDB testing.


